# SOME DESCRIPTIVE TITLE
# Copyright (C) YEAR The Rust Project Developers
# This file is distributed under the same license as the Rust package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Rust 0.9\n"
"POT-Creation-Date: 2014-01-08 11:30+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#. type: Plain text
#: doc/guide-testing.md:2
msgid "% Rust Testing Guide"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:4
msgid "# Quick start"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:6
msgid "To create test functions, add a `#[test]` attribute like this:"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:11
#, no-wrap
msgid ""
"```rust\n"
"fn return_two() -> int {\n"
"    2\n"
"}\n"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:18
#, no-wrap
msgid ""
"#[test]\n"
"fn return_two_test() {\n"
"    let x = return_two();\n"
"    assert!(x == 2);\n"
"}\n"
"```\n"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:20
msgid "To run these tests, use `rustc --test`:"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:25
msgid ""
"``` $ rustc --test foo.rs; ./foo running 1 test test return_two_test ... ok"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:28
msgid "test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured ```"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:31
msgid ""
"`rustc foo.rs` will *not* compile the tests, since `#[test]` implies "
"`#[cfg(test)]`. The `--test` flag to `rustc` implies `--cfg test`."
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:34
msgid "# Unit testing in Rust"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:37
msgid ""
"Rust has built in support for simple unit testing. Functions can be marked "
"as unit tests using the 'test' attribute."
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:44
#, no-wrap
msgid ""
"```rust\n"
"#[test]\n"
"fn return_none_if_empty() {\n"
"    // ... test code ...\n"
"}\n"
"```\n"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:53
msgid ""
"A test function's signature must have no arguments and no return value. To "
"run the tests in a crate, it must be compiled with the '--test' flag: `rustc "
"myprogram.rs --test -o myprogram-tests`. Running the resulting executable "
"will run all the tests in the crate. A test is considered successful if its "
"function returns; if the task running the test fails, through a call to "
"`fail!`, a failed `check` or `assert`, or some other (`assert_eq`, "
"`assert_approx_eq`, ...) means, then the test fails."
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:56
msgid ""
"When compiling a crate with the '--test' flag '--cfg test' is also implied, "
"so that tests can be conditionally compiled."
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:66
#, no-wrap
msgid ""
"```rust\n"
"#[cfg(test)]\n"
"mod tests {\n"
"    #[test]\n"
"    fn return_none_if_empty() {\n"
"      // ... test code ...\n"
"    }\n"
"}\n"
"```\n"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:70
msgid ""
"Additionally #[test] items behave as if they also have the #[cfg(test)] "
"attribute, and will not be compiled when the --test flag is not used."
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:76
msgid ""
"Tests that should not be run can be annotated with the 'ignore' attribute. "
"The existence of these tests will be noted in the test runner output, but "
"the test will not be run. Tests can also be ignored by configuration so, for "
"example, to ignore a test on windows you can write `#[ignore(cfg(target_os = "
"\"win32\"))]`."
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:81
msgid ""
"Tests that are intended to fail can be annotated with the 'should_fail' "
"attribute. The test will be run, and if it causes its task to fail then the "
"test will be counted as successful; otherwise it will be counted as a "
"failure. For example:"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:90
#, no-wrap
msgid ""
"```rust\n"
"#[test]\n"
"#[should_fail]\n"
"fn test_out_of_bounds_failure() {\n"
"    let v: [int] = [];\n"
"    v[0];\n"
"}\n"
"```\n"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:96
msgid ""
"A test runner built with the '--test' flag supports a limited set of "
"arguments to control which tests are run: the first free argument passed to "
"a test runner specifies a filter used to narrow down the set of tests being "
"run; the '--ignored' flag tells the test runner to run only tests with the "
"'ignore' attribute."
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:98
msgid "## Parallelism"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:103
msgid ""
"By default, tests are run in parallel, which can make interpreting failure "
"output difficult. In these cases you can set the `RUST_TEST_TASKS` "
"environment variable to 1 to make the tests run sequentially."
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:105
msgid "## Benchmarking"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:113
msgid ""
"The test runner also understands a simple form of benchmark execution.  "
"Benchmark functions are marked with the `#[bench]` attribute, rather than "
"`#[test]`, and have a different form and meaning. They are compiled along "
"with `#[test]` functions when a crate is compiled with `--test`, but they "
"are not run by default. To run the benchmark component of your testsuite, "
"pass `--bench` to the compiled test runner."
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:120
msgid ""
"The type signature of a benchmark function differs from a unit test: it "
"takes a mutable reference to type `test::BenchHarness`. Inside the benchmark "
"function, any time-variable or \"setup\" code should execute first, followed "
"by a call to `iter` on the benchmark harness, passing a closure that "
"contains the portion of the benchmark you wish to actually measure the per-"
"iteration speed of."
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:126
msgid ""
"For benchmarks relating to processing/generating data, one can set the "
"`bytes` field to the number of bytes consumed/produced in each iteration; "
"this will used to show the throughput of the benchmark.  This must be the "
"amount used in each iteration, *not* the total amount."
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:128 doc/tutorial.md:776
msgid "For example:"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:132
msgid "```rust extern mod extra; use std::vec;"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:138
#, no-wrap
msgid ""
"#[bench]\n"
"fn bench_sum_1024_ints(b: &mut extra::test::BenchHarness) {\n"
"    let v = vec::from_fn(1024, |n| n);\n"
"    b.iter(|| {v.iter().fold(0, |old, new| old + *new);} );\n"
"}\n"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:145
#, no-wrap
msgid ""
"#[bench]\n"
"fn initialise_a_vector(b: &mut extra::test::BenchHarness) {\n"
"    b.iter(|| {vec::from_elem(1024, 0u64);} );\n"
"    b.bytes = 1024 * 8;\n"
"}\n"
"```\n"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:149
msgid ""
"The benchmark runner will calibrate measurement of the benchmark function to "
"run the `iter` block \"enough\" times to get a reliable measure of the per-"
"iteration speed."
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:151
msgid "Advice on writing benchmarks:"
msgstr ""

#. type: Bullet: '  - '
#: doc/guide-testing.md:163
msgid ""
"Move setup code outside the `iter` loop; only put the part you want to "
"measure inside"
msgstr ""

#. type: Bullet: '  - '
#: doc/guide-testing.md:163
msgid ""
"Make the code do \"the same thing\" on each iteration; do not accumulate or "
"change state"
msgstr ""

#. type: Bullet: '  - '
#: doc/guide-testing.md:163
msgid ""
"Make the outer function idempotent too; the benchmark runner is likely to "
"run it many times"
msgstr ""

#. type: Bullet: '  - '
#: doc/guide-testing.md:163
msgid ""
"Make the inner `iter` loop short and fast so benchmark runs are fast and the "
"calibrator can adjust the run-length at fine resolution"
msgstr ""

#. type: Bullet: '  - '
#: doc/guide-testing.md:163
msgid ""
"Make the code in the `iter` loop do something simple, to assist in "
"pinpointing performance improvements (or regressions)"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:166
msgid ""
"To run benchmarks, pass the `--bench` flag to the compiled test-runner. "
"Benchmarks are compiled-in but not executed by default."
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:168
msgid "## Examples"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:170
msgid "### Typical test run"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:173 doc/guide-testing.md:187
msgid "``` > mytests"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:179
msgid ""
"running 30 tests running driver::tests::mytest1 ... ok running driver::"
"tests::mytest2 ... ignored ... snip ...  running driver::tests::mytest30 ... "
"ok"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:182
msgid "result: ok. 28 passed; 0 failed; 2 ignored ```"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:184
msgid "### Test run with failures"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:193
msgid ""
"running 30 tests running driver::tests::mytest1 ... ok running driver::"
"tests::mytest2 ... ignored ... snip ...  running driver::tests::mytest30 ... "
"FAILED"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:196
msgid "result: FAILED. 27 passed; 1 failed; 2 ignored ```"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:198
msgid "### Running ignored tests"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:201
msgid "``` > mytests --ignored"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:205
msgid ""
"running 2 tests running driver::tests::mytest2 ... failed running driver::"
"tests::mytest10 ... ok"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:208
msgid "result: FAILED. 1 passed; 1 failed; 0 ignored ```"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:210
msgid "### Running a subset of tests"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:213
msgid "``` > mytests mytest1"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:219
msgid ""
"running 11 tests running driver::tests::mytest1 ... ok running driver::"
"tests::mytest10 ... ignored ... snip ...  running driver::tests::"
"mytest19 ... ok"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:222
msgid "result: ok. 11 passed; 0 failed; 1 ignored ```"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:224
msgid "### Running benchmarks"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:227
msgid "``` > mytests --bench"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:231
msgid ""
"running 2 tests test bench_sum_1024_ints ... bench: 709 ns/iter (+/- 82)  "
"test initialise_a_vector ... bench: 424 ns/iter (+/- 99) = 19320 MB/s"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:234
msgid "test result: ok. 0 passed; 0 failed; 0 ignored; 2 measured ```"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:236
msgid "## Saving and ratcheting metrics"
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:242
msgid ""
"When running benchmarks or other tests, the test runner can record per-test "
"\"metrics\". Each metric is a scalar `f64` value, plus a noise value which "
"represents uncertainty in the measurement. By default, all `#[bench]` "
"benchmarks are recorded as metrics, which can be saved as JSON in an "
"external file for further reporting."
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:252
msgid ""
"In addition, the test runner supports _ratcheting_ against a metrics file. "
"Ratcheting is like saving metrics, except that after each run, if the output "
"file already exists the results of the current run are compared against the "
"contents of the existing file, and any regression _causes the testsuite to "
"fail_. If the comparison passes -- if all metrics stayed the same (within "
"noise) or improved -- then the metrics file is overwritten with the new "
"values. In this way, a metrics file in your workspace can be used to ensure "
"your work does not regress performance."
msgstr ""

#. type: Plain text
#: doc/guide-testing.md:254
msgid "Test runners take 3 options that are relevant to metrics:"
msgstr ""

#. type: Bullet: '  - '
#: doc/guide-testing.md:263
msgid ""
"`--save-metrics=<file.json>` will save the metrics from a test run to `file."
"json`"
msgstr ""

#. type: Bullet: '  - '
#: doc/guide-testing.md:263
msgid ""
"`--ratchet-metrics=<file.json>` will ratchet the metrics against the `file."
"json`"
msgstr ""

#. type: Bullet: '  - '
#: doc/guide-testing.md:263
msgid ""
"`--ratchet-noise-percent=N` will override the noise measurements in `file."
"json`, and consider a metric change less than `N%` to be noise. This can be "
"helpful if you are testing in a noisy environment where the benchmark "
"calibration loop cannot acquire a clear enough signal."
msgstr ""
